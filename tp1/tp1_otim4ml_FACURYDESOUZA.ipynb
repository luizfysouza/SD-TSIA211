{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stundents\n",
    "\n",
    "Leonel Mota Sampaio Dur√£o\n",
    "\n",
    "Luiz Augusto Facury de Souza"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.1\n",
    "\n",
    "$f_1:(w_0, w) \\longmapsto \\frac{1}{n}  \\sum_{i=1}^{n} log(1+ e^{-y_i(x_i^Tw + w_0)}) + \\frac{\\rho}{2}||w||_2^2$\n",
    "\n",
    "Being $z = y_i(x_i^Tw + w_0)$, we have $\\frac{\\partial z}{w_0} = y_i$ and $\\frac{\\partial z} {w} = y_i x_i^T $\n",
    "\n",
    "$ f_1 = \\frac{1}{n}  \\sum_{i=1}^{n} log(1+ e^{-z}) + \\frac{\\rho}{2}||w||_2^2 $\n",
    "\n",
    "The Gradient is defined by: $\\nabla f_1$ = $\\begin{bmatrix} \\frac{\\partial f_1}{\\partial w_0} \\\\ \\frac{\\partial f_1}{\\partial w} \\end{bmatrix}$ and $\\sigma (z) = \\frac {1}{1+e^z}  $\n",
    "\n",
    "$\\frac{\\partial f_1}{\\partial w_0} = \\frac{1}{n}  \\sum_{i=1}^{n} \\frac{-y_i e^{-z}}{1+ e^{-z}} = \\frac{1}{n}  \\sum_{i=1}^{n} -y_i e^{-z} \\sigma(z)$\n",
    "\n",
    "$\\frac{\\partial f_1}{\\partial w} = \\frac{1}{n}  \\sum_{i=1}^{n} \\frac{-y_i x_i^T e^{-z}}{1+ e^{-z}} + \\rho w = \\frac{1}{n}  \\sum_{i=1}^{n} -y_i x_i^T e^{-z} \\sigma(z) + \\rho w$\n",
    "\n",
    "Calculating the Hessian\n",
    "\n",
    "Quotient rule: $\\frac{d}{dx} \\frac{f(x)}{g(x)} = \\frac{f'(x)g(x) - f(x)g'(x)}{g(x)^2}$\n",
    "\n",
    "\n",
    "\n",
    "$\\nabla^2 f_1$ = $\\begin{bmatrix} \\frac{\\partial^2 f_1}{\\partial w_0^2} & \\frac{\\partial^2 f_1}{\\partial w_0 \\partial w} \\\\ \\frac{\\partial^2 f_1}{\\partial w \\partial w_0} & \\frac{\\partial^2 f_1}{\\partial w^2} \\end{bmatrix}$\n",
    "\n",
    "$\\frac{\\partial^2 f_1}{\\partial w_0^2} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{(y_i^2 e^{-z})(1 + e^{-z}) - (-y_i e^{-z}) (-y_i e^{-z})}{(1+ e^{-z})^2}      =     \\frac{1}{n} \\sum_{i=1}^{n} \\frac{y_i^2 e^{-z} + y_i^2 e^{-2z} - y_i^2 e^{-2z}}{(1+ e^{-z})^2}    =   \\frac{1}{n} \\sum_{i=1}^{n} \\frac{y_i^2 e^{-z}}{(1+ e^{-z})^2} $\n",
    "\n",
    "$\\frac{\\partial^2 f_1}{\\partial w_0 \\partial w} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{y_i^2 x_i^T e^{-z}}{(1+ e^{-z})^2}$\n",
    "\n",
    "$\\frac{\\partial^2 f_1}{\\partial w \\partial w_0} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{y_i^2 x_i^T e^{-z}}{(1+ e^{-z})^2}$\n",
    "\n",
    "$\\frac{\\partial^2 f_1}{\\partial w^2} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{y_i^2 (x_i^T)^2 e^{-z}}{(1+ e^{-z})^2} + \\rho I$\n",
    "\n",
    "Determinant of Hessian\n",
    "\n",
    "$det(\\nabla^2 f_1) = \\frac{1}{n^2} \\sum_{i=1}^{n} \\frac{y_i^2 e^{-z}}{(1+ e^{-z})^2} * (\\frac{1}{n} \\sum_{i=1}^{n} \\frac{y_i^2 (x_i^T)^2 e^{-z}}{(1+ e^{-z})^2} + \\rho) - (\\frac{1}{n^2} \\sum_{i=1}^{n} \\frac{y_i^2 x_i^T e^{-z}}{(1+ e^{-z})^2})^2$\n",
    "\n",
    "Therefore, the function is convex, since its determinant is strictly positive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f1(w0, w, X, y, rho):\n",
    "    # Calculate the dot product of X and w\n",
    "    dot_product = np.dot(X, w)\n",
    "    # Calculate w0 + dot_product\n",
    "    w0_dot = w0 + dot_product\n",
    "    # Calculate -y_i*(w0_dot)\n",
    "    y_w0_dot = -y * w0_dot\n",
    "    # Calculate log(1 + e^(y_w0_dot))\n",
    "    log_term = np.log(1 + np.exp(y_w0_dot))\n",
    "    # Calculate the sum of log_term\n",
    "    sum_log_term = np.sum(log_term)\n",
    "    # Calculate the first term of the function\n",
    "    first_term = sum_log_term\n",
    "    # Calculate the second term of the function\n",
    "    second_term = (rho/2) * np.dot(w, w)\n",
    "    # Return the sum of the two terms\n",
    "    return first_term + second_term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def grad_f1(w_0, w, X, y, rho):\n",
    "    print (y)\n",
    "    n = len(y)\n",
    "    z = y * (X.dot(w) + w_0)\n",
    "    sig = 1 / (1 + np.exp(-z))\n",
    "    grad_w_0 = -1/n * (y * np.exp(-z) * sig).sum()\n",
    "    grad_w = -1/n * (X.T.dot(y * np.exp(-z) * sig)) + rho * w\n",
    "    return grad_w_0, grad_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient wrt w_0: 0.5284756798647275\n",
      "Gradient wrt w: 2.602990013593906\n"
     ]
    }
   ],
   "source": [
    "# Sample input data\n",
    "X = np.array([1,2,3,4,5,6,7]) # (3, 3)\n",
    "y = np.array([1, -1, 1,1,-2,-1,1]) # (3,)\n",
    "w_0 = 0.5\n",
    "w = 1 # (3,)\n",
    "rho = 0.1\n",
    "\n",
    "# Compute the gradient\n",
    "grad_w_0, grad_w = grad_f1(w_0, w, X, y, rho)\n",
    "\n",
    "print(\"Gradient wrt w_0:\", grad_w_0)\n",
    "print(\"Gradient wrt w:\", grad_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian_logreg_l2_1D(X, y, w, w_0, rho):\n",
    "    n = len(y)\n",
    "    z = y * (X*w + w_0)\n",
    "    sig = 1 / (1 + np.exp(-z))\n",
    "    diag_sig = np.diag(sig * (1 - sig))\n",
    "    Hessian_w_0_w_0 = 1/n * ((y**2) * sig * (1 - sig)).sum()\n",
    "    Hessian_w_0_w = 1/n * (y * X.T.dot(diag_sig))\n",
    "    Hessian_w_w_0 = 1/n * (y * X.T.dot(diag_sig))\n",
    "    Hessian_w_w = 1/n * X.T.dot(X * diag_sig) + rho * np.eye(1)\n",
    "    return np.array([[Hessian_w_0_w_0, Hessian_w_0_w[0]], [Hessian_w_w_0[0], Hessian_w_w[0][0]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hessian: \n",
      " [[0.03724109 0.02130664]\n",
      " [0.02130664 0.12130664]]\n"
     ]
    }
   ],
   "source": [
    "# Compute the Hessian\n",
    "hessian = hessian_logreg_l2_1D(X, y, w, w_0, rho)\n",
    "\n",
    "print(\"Hessian: \\n\", hessian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([138562,    575])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.load('tfidf_matrix_97MB/data.npy')\n",
    "y = np.load('train_labels.npy', allow_pickle=True)\n",
    "np.load('tfidf_matrix_97MB/shape.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1  1  1 -2 -1  1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_190346/3630132453.py:7: RuntimeWarning: overflow encountered in exp\n",
      "  sig = 1 / (1 + np.exp(-z))\n",
      "/tmp/ipykernel_190346/3630132453.py:8: RuntimeWarning: overflow encountered in exp\n",
      "  grad_w_0 = -1/n * (y * np.exp(-z) * sig).sum()\n",
      "/tmp/ipykernel_190346/3630132453.py:8: RuntimeWarning: invalid value encountered in multiply\n",
      "  grad_w_0 = -1/n * (y * np.exp(-z) * sig).sum()\n",
      "/tmp/ipykernel_190346/3630132453.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  grad_w = -1/n * (X.T.dot(y * np.exp(-z) * sig)) + rho * w\n",
      "/tmp/ipykernel_190346/3630132453.py:9: RuntimeWarning: invalid value encountered in multiply\n",
      "  grad_w = -1/n * (X.T.dot(y * np.exp(-z) * sig)) + rho * w\n",
      "/tmp/ipykernel_190346/3493810218.py:11: RuntimeWarning: overflow encountered in exp\n",
      "  log_term = np.log(1 + np.exp(y_w0_dot))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import check_grad\n",
    "rho = 0.5\n",
    "check_grad(f1, grad_f1, w_0, w, X, y, rho)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_logreg_l2_1D(X, y, w, w_0, rho, max_iter=1000, tol=1e-6):\n",
    "    n = len(y)\n",
    "    for i in range(max_iter):\n",
    "        z = y * (X*w + w_0)\n",
    "        sig = 1 / (1 + np.exp(-np.clip(z, -250, 250)))\n",
    "        diag_sig = np.diag(sig * (1 - sig))\n",
    "        gradient_w_0 = -1/n * (y * sig).sum()\n",
    "        gradient_w = -1/n * X.T.dot(y * sig) + rho * w\n",
    "        hessian_w_0_w_0 = 1/n * ((y**2) * sig * (1 - sig)).sum()\n",
    "        hessian_w_0_w = 1/n * (y * X.T.dot(diag_sig))\n",
    "        hessian_w_w_0 = 1/n * (y * X.T.dot(diag_sig))\n",
    "        hessian_w_w = 1/n * X.T.dot(X * diag_sig) + rho * np.eye(1)\n",
    "        hessian = np.array([[hessian_w_0_w_0, hessian_w_0_w[0]], [hessian_w_w_0[0], hessian_w_w[0][0]]])\n",
    "        update_w_0, update_w = np.linalg.solve(hessian, [-gradient_w_0, -gradient_w])\n",
    "        w_0 += update_w_0\n",
    "        w += update_w\n",
    "        if np.linalg.norm(update_w) < tol:\n",
    "            break\n",
    "    return w_0, w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the norm of the gradient as a function of iterations in logarithmic scale\n",
    "import matplotlib.pyplot as plt\n",
    "rho = 0.2\n",
    "w_0 = 0\n",
    "w = 0\n",
    "\n",
    "def plot_norm_grad(X, y, w, w_0, rho, max_iter=1000, tol=1e-6):\n",
    "    n = len(y)\n",
    "    norm_grad = []\n",
    "    for i in range(max_iter):\n",
    "        z = y * (X*w + w_0)\n",
    "        sig = 1 / (1 + np.exp(-np.clip(z, -250, 250)))\n",
    "        diag_sig = np.diag(sig * (1 - sig))\n",
    "        gradient_w_0 = -1/n * (y * sig).sum()\n",
    "        gradient_w = -1/n * X.T.dot(y * sig) + rho * w\n",
    "        hessian_w_0_w_0 = 1/n * ((y**2) * sig * (1 - sig)).sum()\n",
    "        hessian_w_0_w = 1/n * (y * X.T.dot(diag_sig))\n",
    "        hessian_w_w_0 = 1/n * (y * X.T.dot(diag_sig))\n",
    "        hessian_w_w = 1/n * X.T.dot(X * diag_sig) + rho * np.eye(1)\n",
    "        hessian = np.array([[hessian_w_0_w_0, hessian_w_0_w[0]], [hessian_w_w_0[0], hessian_w_w[0][0]]])\n",
    "        update_w_0, update_w = np.linalg.solve(hessian, [-gradient_w_0, -gradient_w])\n",
    "        w_0 += update_w_0\n",
    "        w += update_w\n",
    "        norm_grad.append(np.linalg.norm(gradient_w))\n",
    "        if np.linalg.norm(update_w) < tol:\n",
    "            break\n",
    "    plt.plot(norm_grad)\n",
    "    plt.yscale('log')\n",
    "    plt.show()\n",
    "    return w_0, w\n",
    "\n",
    "w_0, w = plot_norm_grad(X, y, w, w_0, rho)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.995272819336898e+108, 21.428571428571427)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rho = 0.1\n",
    "newton_logreg_l2_1D(X, y, 1, 1, rho, tol = 1e-10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretically, the algorithm should converge to the minimum of the function, since the function is convex and the gradient is Lipschitz continuous. However, if (w0, w) is 1, you may observe that the method is unable to converge to a solution. This is because the initial point is not a good starting point for the optimization problem.The reason is that, Newton's method is a second order optimization method which means that it uses the information of the Hessian matrix in order to converge to a solution. if the initial point is not in a suitable region, the Hessian matrix might be not invertible or close to it, and the optimization algorithm will be unable to converge."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def armijo_line_search(x, y, w, w_0, rho, grad, hessian, alpha=0.5, beta=0.5):\n",
    "    step_size = 1\n",
    "    hessian_inv = np.linalg.inv(hessian)\n",
    "    while f1(x, y, w + step_size * hessian_inv.dot(grad)[1], w_0 + step_size * hessian_inv.dot(grad)[0], rho) > f1(x, y, w, w_0, rho) + alpha * step_size * grad.T.dot(hessian_inv).dot(grad):\n",
    "        step_size *= beta\n",
    "    return step_size\n",
    "\n",
    "def newton_logreg_l2(x, y, w, w_0, rho, max_iter=1000, tol=1e-6):\n",
    "    for i in range(max_iter):\n",
    "        grad = grad_f1(x, y, w, w_0, rho)\n",
    "        hessian = hessian_logreg_l2_1D(x, y, w, w_0, rho)\n",
    "        hessian_inv = np.linalg.inv(hessian)\n",
    "        step_size = armijo_line_search(x, y, w, w_0, rho, grad, hessian_inv)\n",
    "        update_w_0, update_w = step_size * hessian_inv.dot(grad)\n",
    "        w_0 += update_w_0\n",
    "        w += update_w\n",
    "        if np.linalg.norm(update_w) < tol:\n",
    "            break\n",
    "    return w_0, w\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alpha is a parameter that controls the minimum amount of decrease required for the step size to be considered \"sufficient\", it is normally between 0,1 and 0.5. Beta is another parameter that controls the rate at which the step size is reduced, the value is also small, but can be a bit higher."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the l1 norm does not approach 0 as $w$ approaches its minimum, the Newton's method does not work."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective function can be written as:\n",
    "\n",
    "$F2(w, w_0) = f2(w, w_0) + g2(w)$\n",
    "\n",
    "where:\n",
    "\n",
    "$f2(w, w_0) = \\frac{1}{n} \\sum_{i=1}^n log(1 + e^{-y_i(x_i^Tw + w_0)})$\n",
    "\n",
    "$g2(w) = \\rho ||w||_1$\n",
    "\n",
    "The proximal operator of g2 is defined as:\n",
    "\n",
    "$prox_{g2}(w, t) = sign(w) * max(|w| - t, 0)$\n",
    "\n",
    "where $sign(w)$ is the element-wise sign of $w$ and $t$ is the step size."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient of $f_2$ with respect to $w_0$ is:\n",
    "\n",
    "$\\frac{\\partial f_2}{\\partial w_0} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{-y_i e^{-y_i(x_i^Tw + w_0)}}{1+ e^{-y_i(x_i^Tw + w_0)}}$\n",
    "\n",
    "The gradient of $f_2$ with respect to $w$ is:\n",
    "\n",
    "$\\frac{\\partial f_2}{\\partial w} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{-y_i x_i e^{-y_i(x_i^Tw + w_0)}}{1+ e^{-y_i(x_i^Tw + w_0)}}$\n",
    "\n",
    "It's important to note that as it is, this is the gradient of the logistic loss function, which is differentiable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(x, y, w, w_0, rho):\n",
    "    return np.log(1 + np.exp(-y * (w_0 + x.dot(w)))).sum() + rho * np.linalg.norm(w)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proximal_gradient_method_l1(X, y, rho = 0.02, max_iter = 1000, epsilon = 1e-6):\n",
    "    n, d = X.shape\n",
    "    w = np.zeros(d)\n",
    "    w_0 = 0\n",
    "    alpha = 0.5\n",
    "    beta = 0.8\n",
    "    t = 1\n",
    "    for i in range(max_iter):\n",
    "        z = y * (X.dot(w) + w_0)\n",
    "        sig = 1 / (1 + np.exp(-z))\n",
    "        grad_w_0 = (-1/n) * y.dot(sig)\n",
    "        grad_w = (-1/n) * X.T.dot(y * sig) + rho * np.sign(w)\n",
    "        prev_w = w\n",
    "        prev_w_0 = w_0\n",
    "        w_0 = w_0 - t * grad_w_0\n",
    "        w = w - t * grad_w\n",
    "        w = np.maximum(w - t*rho, 0) + np.minimum(w + t*rho, 0)\n",
    "        while f2(X, y, w, w_0) > f2(X, y, prev_w, prev_w_0) + alpha * t * (grad_w.T.dot(w - prev_w) + grad_w_0 * (w_0 - prev_w_0)):\n",
    "            t = beta * t\n",
    "            w_0 = prev_w_0 - t * grad_w_0\n",
    "            w = prev_w - t * grad_w\n",
    "            w = np.maximum(w - t*rho, 0) + np.minimum(w + t*rho, 0)\n",
    "        if (np.linalg.norm(grad_w) < epsilon) and (np.abs(grad_w_0) < epsilon):\n",
    "            break\n",
    "    return w, w_0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stopping test that i suggest is to check if the norm of the gradient is less than a certain tolerance (epsilon). This would mean that the function is close enough to a local minimum and the algorithm can stop.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
